{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JZfbyRVgZFZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3934
        },
        "outputId": "d0757e5e-714c-4917-f92b-82bcec3df65a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
        "\n",
        "#定义神经层\n",
        "def add_layer(inputs,in_size,outsize,activation_function=None):\n",
        "    Weights=tf.Variable(tf.random_normal([in_size,outsize]))\n",
        "    biases=tf.Variable(tf.zeros([outsize])+0.1)\n",
        "\n",
        "    Wx_plus_b=tf.matmul(inputs,Weights)+biases\n",
        "\n",
        "    if activation_function is None:\n",
        "        outputs=Wx_plus_b\n",
        "    else:\n",
        "        outputs=activation_function(Wx_plus_b)\n",
        "    return outputs\n",
        "\n",
        "def compute_accuracy(v_xs,v_ys):\n",
        "    global prediction\n",
        "    y_pre=sess.run(prediction,feed_dict={xs:v_xs})\n",
        "    correct_prediction=tf.equal(tf.argmax(y_pre,1),tf.argmax(v_ys,1))\n",
        "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "    result=sess.run(accuracy,feed_dict={xs:v_xs,ys:v_ys})\n",
        "    return result\n",
        "\n",
        "xs=tf.placeholder(tf.float32,[None,784])\n",
        "ys=tf.placeholder(tf.float32,[None,10])\n",
        "\n",
        "prediction=add_layer(xs,784,10,activation_function=tf.nn.softmax)\n",
        "\n",
        "cross_entropy=tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction),reduction_indices=[1]))\n",
        "train_step=tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
        "\n",
        "sess=tf.Session()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "for i in range(10000):\n",
        "    batch_xs,batch_ys=mnist.train.next_batch(100)\n",
        "    sess.run(train_step,feed_dict={xs:batch_xs,ys:batch_ys})\n",
        "    if i %50==0:\n",
        "        print(compute_accuracy(mnist.test.images,mnist.test.labels))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-7300a44aa8f5>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "0.1108\n",
            "0.6567\n",
            "0.7487\n",
            "0.7857\n",
            "0.8037\n",
            "0.8214\n",
            "0.8306\n",
            "0.8382\n",
            "0.8509\n",
            "0.8537\n",
            "0.8544\n",
            "0.8583\n",
            "0.8595\n",
            "0.862\n",
            "0.8664\n",
            "0.866\n",
            "0.8717\n",
            "0.8717\n",
            "0.8697\n",
            "0.8758\n",
            "0.8746\n",
            "0.8785\n",
            "0.8722\n",
            "0.8767\n",
            "0.8769\n",
            "0.8819\n",
            "0.8775\n",
            "0.8809\n",
            "0.885\n",
            "0.8852\n",
            "0.8825\n",
            "0.8867\n",
            "0.8872\n",
            "0.8862\n",
            "0.8849\n",
            "0.8881\n",
            "0.889\n",
            "0.8859\n",
            "0.8887\n",
            "0.8901\n",
            "0.8888\n",
            "0.89\n",
            "0.8906\n",
            "0.8915\n",
            "0.8925\n",
            "0.8931\n",
            "0.8947\n",
            "0.8948\n",
            "0.8951\n",
            "0.8956\n",
            "0.8954\n",
            "0.8955\n",
            "0.8975\n",
            "0.8918\n",
            "0.8976\n",
            "0.8953\n",
            "0.8962\n",
            "0.8974\n",
            "0.8967\n",
            "0.898\n",
            "0.8979\n",
            "0.8984\n",
            "0.899\n",
            "0.8998\n",
            "0.8963\n",
            "0.8988\n",
            "0.9007\n",
            "0.9012\n",
            "0.898\n",
            "0.8996\n",
            "0.9016\n",
            "0.8979\n",
            "0.8992\n",
            "0.9003\n",
            "0.899\n",
            "0.8978\n",
            "0.899\n",
            "0.9016\n",
            "0.8984\n",
            "0.9033\n",
            "0.9037\n",
            "0.9016\n",
            "0.9007\n",
            "0.9049\n",
            "0.9035\n",
            "0.9043\n",
            "0.9047\n",
            "0.904\n",
            "0.9012\n",
            "0.9038\n",
            "0.9029\n",
            "0.9038\n",
            "0.9016\n",
            "0.9036\n",
            "0.9051\n",
            "0.9007\n",
            "0.9036\n",
            "0.9063\n",
            "0.9037\n",
            "0.9071\n",
            "0.9034\n",
            "0.9055\n",
            "0.9052\n",
            "0.9071\n",
            "0.904\n",
            "0.9055\n",
            "0.9071\n",
            "0.908\n",
            "0.9061\n",
            "0.9091\n",
            "0.9067\n",
            "0.905\n",
            "0.9034\n",
            "0.9069\n",
            "0.9067\n",
            "0.9051\n",
            "0.9054\n",
            "0.9071\n",
            "0.9081\n",
            "0.9046\n",
            "0.9078\n",
            "0.9076\n",
            "0.9079\n",
            "0.906\n",
            "0.9058\n",
            "0.8937\n",
            "0.9072\n",
            "0.9084\n",
            "0.9024\n",
            "0.9081\n",
            "0.9059\n",
            "0.9101\n",
            "0.9063\n",
            "0.911\n",
            "0.9009\n",
            "0.9082\n",
            "0.9096\n",
            "0.9098\n",
            "0.9089\n",
            "0.9091\n",
            "0.9095\n",
            "0.909\n",
            "0.9109\n",
            "0.9087\n",
            "0.9094\n",
            "0.9125\n",
            "0.9107\n",
            "0.912\n",
            "0.9097\n",
            "0.9109\n",
            "0.9008\n",
            "0.91\n",
            "0.9094\n",
            "0.9118\n",
            "0.909\n",
            "0.9092\n",
            "0.9076\n",
            "0.9105\n",
            "0.9109\n",
            "0.9107\n",
            "0.9124\n",
            "0.9033\n",
            "0.9118\n",
            "0.9093\n",
            "0.9107\n",
            "0.9116\n",
            "0.9127\n",
            "0.9126\n",
            "0.9101\n",
            "0.9109\n",
            "0.9133\n",
            "0.9095\n",
            "0.911\n",
            "0.9111\n",
            "0.9087\n",
            "0.9095\n",
            "0.9111\n",
            "0.9113\n",
            "0.9087\n",
            "0.9106\n",
            "0.912\n",
            "0.9094\n",
            "0.9124\n",
            "0.911\n",
            "0.9121\n",
            "0.9142\n",
            "0.9131\n",
            "0.9131\n",
            "0.912\n",
            "0.9089\n",
            "0.9125\n",
            "0.9115\n",
            "0.9112\n",
            "0.9102\n",
            "0.9121\n",
            "0.9058\n",
            "0.9097\n",
            "0.9153\n",
            "0.9128\n",
            "0.9146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-fLXxCDLboEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2db3d488-7912-4181-93fa-7f12f556bf1f"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.labels.shape)\n",
        "print(mnist.test.labels[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "clsOEzVpb0j8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2335
        },
        "outputId": "843f0571-0b91-4d16-e1b8-3471809940ca"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.images)\n",
        "print(mnist.test.images[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.32941177 0.7254902\n",
            " 0.62352943 0.5921569  0.23529413 0.14117648 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.8705883  0.9960785  0.9960785  0.9960785\n",
            " 0.9960785  0.9450981  0.77647066 0.77647066 0.77647066 0.77647066\n",
            " 0.77647066 0.77647066 0.77647066 0.77647066 0.6666667  0.20392159\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.2627451  0.44705886 0.28235295 0.44705886 0.6392157  0.89019614\n",
            " 0.9960785  0.882353   0.9960785  0.9960785  0.9960785  0.9803922\n",
            " 0.8980393  0.9960785  0.9960785  0.54901963 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.06666667 0.25882354 0.05490196\n",
            " 0.2627451  0.2627451  0.2627451  0.23137257 0.08235294 0.92549026\n",
            " 0.9960785  0.4156863  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3254902  0.9921569  0.8196079  0.07058824\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.08627451\n",
            " 0.91372555 1.         0.3254902  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.5058824  0.9960785  0.9333334\n",
            " 0.17254902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.23137257 0.97647065 0.9960785  0.24313727 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.52156866 0.9960785\n",
            " 0.73333335 0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.03529412 0.80392164 0.9725491  0.227451   0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.49411768\n",
            " 0.9960785  0.7137255  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.29411766 0.9843138  0.94117653 0.22352943\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.07450981\n",
            " 0.86666673 0.9960785  0.6509804  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.7960785  0.9960785  0.8588236\n",
            " 0.13725491 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14901961 0.9960785  0.9960785  0.3019608  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.12156864 0.87843144 0.9960785\n",
            " 0.45098042 0.00392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.52156866 0.9960785  0.9960785  0.20392159 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.2392157  0.9490197\n",
            " 0.9960785  0.9960785  0.20392159 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.47450984 0.9960785  0.9960785  0.8588236\n",
            " 0.15686275 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.47450984 0.9960785  0.8117648  0.07058824 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MS_qfX7kcAKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94295429-c61b-41ee-80a9-03e700accecf"
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.images.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}